---
title: ""
layout: home
permalink: /
classes: wide
redirect_from:
  - /portfolio/
  - /portfolio
---

## About Me

I am a Research Engineer at the [Robotics and Dynamical Systems Lab](https://labs.engineering.asu.edu/rads/person/sangram-redkar/), where I pursue my passion for robotics and machine learning. My research focuses on developing control systems for locomotion, photorealistic simulations, and curating data for robot learning.

I earned my M.S. in Robotics and Autonomous Systems from Arizona State University and my B.Tech. in Mechatronics Engineering from NMIMS University in Mumbai. I successfully defended my Master's [thesis](https://www.proquest.com/docview/3202787059?sourcetype=Dissertations%20&%20Theses) at ASU, which involved creating a digital twin of a bio-inspired worm/snake robot using [Nvidia Isaac SIM](https://developer.nvidia.com/isaac/sim). This research was funded by [TSMC](https://www.tsmc.com/english) Arizona.

## Professional Experience
<table>
  <tbody>
    <tr>
      <td style = "border-bottom-width:0;"><img src="{{site.baseurl}}/assets/images/bio/tsmc_logo.jpeg" alt="tsmc" width="60"></td>
      <td style = "border-bottom-width:0;">
        <strong>TSMC Arizona</strong> <br> 08/2024 - 05/2025 <br> Research Fellow</td>
      <td style = "border-bottom-width:0;"><img src="{{site.baseurl}}/assets/images/bio/unilever_logo.jpeg" alt="unilever" width="60"></td>
      <td style = "border-bottom-width:0;">
        <strong>Unilever</strong> <br> 11/2022 - 07/2023 <br> Robotics/Automation Developer</td>
      <td style="border-bottom-width:0;"><img src="{{site.baseurl}}/assets/images/bio/mahindragroup_logo.jpeg" alt="mahindra" width="60"></td>
      <td style="border-bottom-width:0;">
        <strong>Mahindra Automotive</strong> <br> 07/2021 - 07/2022 <br> Robotics Engineer </td>
    </tr>
  </tbody>
</table>

## Education
<table>
  <tbody>
    <tr>
      <td style="border-bottom-width:0;"><img src="{{site.baseurl}}/assets/images/bio/asu.jpeg" alt="asu" width="60"></td>
      <td style="border-bottom-width:0;">
        <strong>Arizona State University</strong> <br> 08/2023 - 05/2025 <br> M.S. in Robotics & Autonomous Systems (Thesis)
      </td>
      <td style="border-bottom-width:0;"><img src="{{site.baseurl}}/assets/images/bio/nmims.jpeg" alt="nmims" width="60"></td>
      <td style="border-bottom-width:0;">
        <strong>NMIMS University</strong> <br> 07/2017 - 06/2021 <br> B.Tech. in Mechatronics Engineering, <em>Minored in Robotics & Internet of Things</em>
      </td>
    </tr>
  </tbody>
</table>


## Patent & Publications

<div class="container">
  <div class="image-container">
    <a href="https://doi.org/10.1115/1.4068629">
      <img src="{{site.baseurl}}/assets/images/bio/publications/fpid1.png" alt="asme1">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="https://doi.org/10.1115/1.4068629" class="title-link">
        <h3>A Novel Real-Time Data-Driven Fractional-Order Proportional–Integral–Derivative Control of a Worm Robot Using Koopman Theory (ASME)</h3>
      </a>
    </div>
    <div class="text-content">
      <p>We present a control strategy for worm-like robots that combines PID, MPC, and FOPID controllers with a neural Koopman operator to manage nonlinear locomotion dynamics. By lifting system dynamics into a linear space and updating the model at each timestep, we enable accurate, adaptable control. Experiments and simulations confirm improved trajectory tracking and stability under uncertain conditions.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="https://www.cambridge.org/core/journals/robotica/article/compound-koopman-datadriven-control-for-an-inchworm-robot-validation-through-virtual-experiments/46361FE83A4526E60866FA93176714EB?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark">
      <img src="{{site.baseurl}}/assets/images/bio/publications/koop.png" alt="rob1">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="https://www.cambridge.org/core/journals/robotica/article/compound-koopman-datadriven-control-for-an-inchworm-robot-validation-through-virtual-experiments/46361FE83A4526E60866FA93176714EB?utm_campaign=shareaholic&utm_medium=copy_link&utm_source=bookmark" class="title-link">
        <h3>Compound Koopman data-driven control for an inchworm robot: validation through virtual experiments (Cambridge Robotica)</h3>
      </a>
    </div>
    <div class="text-content">
      <p>We introduce a data-driven control framework for inchworm robots that combines fractional PID (FPID) control with Koopman operator theory. By training a neural network to model nonlinear dynamics in a lifted linear space, our method enables more systematic and scalable control design. Deployed within NVIDIA Isaac Sim, the approach outperforms conventional methods in trajectory tracking and locomotion efficiency, offering a robust solution for complex, bio-inspired robotics.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="">
      <img src="{{site.baseurl}}/assets/images/bio/publications/design.png" alt="design">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="" class="title-link">
        <h3>Design Patent - Helmet for real-time AR/VR training tasks in manufacturing</h3>
      </a>
    </div>
    <div class="text-content">
      <p>Application Number: 375891-001 , PROTECTIVE HELMET (03/2023) in <a href="https://search.ipindia.gov.in/IPOJournal/Journal/Patent" target="_blank">Patent and Design Journal</a> <br> Copyright was issued for the same project regarding a training module developed in Unity. It can be found <a href="https://copyright.gov.in/SearchRoc.aspx" target="_blank">here</a> under the diary number of 4912/2023-CO/CF </p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="">
      <img src="{{site.baseurl}}/assets/images/bio/publications/asme-logo.jpeg" alt="asme2" width="60">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="" class="title-link">
        <h3>Analysis of Inverse Kinematics for 5 DOF Caterpillar Robot (ASME) [Under Review]</h3>
      </a>
    </div>
    <div class="text-content">
      <p>Inverse Kinematics validation of 5 DOF Caterpillar robot using Nvidia Isaac SIM.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="">
      <img src="{{site.baseurl}}/assets/images/bio/publications/ieee-logo.jpeg" alt="ieee1">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="" class="title-link">
        <h3>Digital Twin of a Worm Robot [In Preparation]</h3>
      </a>
    </div>
    <div class="text-content">
      <p>Showcases the entire digital twin loop that helps real robot move and generate data for physically accurate simulation in real time. This helps us test and validate the robot in multiple environments and gauge performance. The paper will be entered into the next IEEE conference.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="">
      <img src="{{site.baseurl}}/assets/images/bio/publications/ieee-logo.jpeg" alt="ieee2">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="" class="title-link">
        <h3>Language-driven control for worm robot and validation using Digital Twin [In Preparation]</h3>
      </a>
    </div>
    <div class="text-content">
      <p>Developing LLM based control for moving a 9 DOF snake robot in XY plane. This robot now includes sidewinding as well.</p>
    </div>
  </div>
</div>

## Past Projects

<div class="container">
  <div class="image-container">
    <a href="/portfolio_manipulation/worm">
      <img src="{{site.baseurl}}/assets/images/thesis/thesis2.gif" alt="worm">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_manipulation/worm" class="title-link">
        <h3>Thesis: Bio-Inspired Worm Robot</h3>
      </a>
    </div>
    <div class="text-content">
      <p>This project involves the design and control of a 5-DOF worm-inspired robot capable of metachronal gait generation using Euler-Lagrange dynamics, geometric algebra, and fractional PID and Koopman-based control. A photorealistic digital twin in Isaac Sim validates real-time behavior and enables closed-loop feedback for adaptive locomotion in unstructured terrains.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_ML/balance-bracelet">
      <img src="{{site.baseurl}}/assets/images/coherent-device/main.png" alt="emotion-detection">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_ML/balance-bracelet" class="title-link">
        <h3>Balance Bracelet for Coherent Breathing Biofeedback</h3>
      </a>
    </div>
    <div class="text-content">
      <p>This study highlights the potential of coherent breathing, facilitated by a wearable device, in enhancing heart rate variability and respiratory synchronization. The Balance Bracelet could offer clinicians a non-pharmacological tool to assist patients in managing stress and improving cardiovascular health. Regular use of this technique could lead to better outcomes in patients suffering from stress-related disorders, making it a valuable addition to therapeutic strategies.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_perception_nav/liosam">
      <img src="{{site.baseurl}}/assets/gifs/liosam.gif" alt="liosam">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_perception_nav/liosam" class="title-link">
        <h3>LIOSAM : Tightly-coupled Lidar Inertial Odometry via Smoothing and Mapping</h3>
      </a>
    </div>
    <div class="text-content">
      <p>LIO-SAM is a tightly-coupled LiDAR-Inertial Odometry system that integrates IMU pre-integration with LiDAR scan-matching within a factor graph framework, enabling accurate and real-time 3D mapping and localization. It is particularly effective in environments where GPS signals are weak or unavailable, such as indoors or urban canyons.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_ML/dsp-ml">
      <img src="{{site.baseurl}}/assets/images/dsp/dsp.png" alt="dsp-ml">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_ML/dsp-ml" class="title-link">
        <h3>Digit Recognition using Speech Spectrograms</h3>
      </a>
    </div>
    <div class="text-content">
      <p>This project explores the classification of spoken digits by converting audio signals into spectrograms and applying convolutional neural networks (CNNs). While achieving 100% accuracy on clean data, the model's performance drops to 88.33% with noisy inputs, highlighting the critical role of data quality and preprocessing in speech recognition systems.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_perception_nav/slam">
      <img src="{{site.baseurl}}/assets/gifs/slam/navsim.gif" alt="slam">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_perception_nav/slam" class="title-link">
        <h3>Autonomous Navigation with TurtleBot3 Burger (ROS Noetic)</h3>
      </a>
    </div>
    <div class="text-content">
      <p>This project implements autonomous navigation on the TurtleBot3 Burger using ROS Noetic. It integrates SLAM, AMCL-based localization, and path planning to enable the robot to map and navigate real-world environments.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_manipulation/ur5">
      <img src="{{site.baseurl}}/assets/gifs/slam/ur5.gif" alt="ur5">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_manipulation/ur5" class="title-link">
        <h3>UR5 Palletizing: Dual-Mode Implementation with Teach Pendant and ROS2</h3>
      </a>
    </div>
    <div class="text-content">
      <p>This project implements a UR5 robot performing a pick-and-place palletizing task, initially programmed using the UR Teach Pendant's graphical interface for direct control, and subsequently replicated in a ROS2 simulation environment with Gazebo and MoveIt for enhanced flexibility and integration.</p>
    </div>
  </div>
</div>

<div class="container">
  <div class="image-container">
    <a href="/portfolio_manipulation/mycobot-simscape">
      <img src="{{site.baseurl}}/assets/gifs/mycobot/mycobot-simscape.gif" alt="mycobot1">
    </a>
  </div>
  <div class="text-container">
    <div class="header-row">
      <a href="/portfolio_manipulation/mycobot-simscape" class="title-link">
        <h3>Kinematic Analysis and Simulation of MyCobot280 M5 using MATLAB and Simscape</h3>
      </a>
    </div>
    <div class="text-content">
      <p>Developed a comprehensive digital twin of the MyCobot 280 M5 robotic arm using MATLAB and Simscape Multibody, integrating CAD-based modeling with forward and inverse kinematics. Validated simulation results through real-time control via the <code>pymycobot</code> Python API, ensuring alignment between virtual models and physical hardware performance.</p>
    </div>
  </div>
</div>


<style>
.container {
  display: flex;
  margin-bottom: 10px;
  gap: 10px;
}

.image-container {
  flex: 0 0 200px;
  height: 100px;
  overflow: hidden;
}

.image-container img {
  width: 100%;
  height: 100%;
  object-fit: cover;
  object-position: center;
  display: block;
  transition: opacity 0.2s;
}

/* Special handling for logo-style images in the experience/education tables */
table img {
  width: 60px;
  height: 60px;
  object-fit: contain;
}

.image-container img:hover {
  opacity: 0.8;
}

.text-container {
  flex: 1;
  display: flex;
  flex-direction: column;
  min-height: 100px;
  justify-content: flex-start;
}

.header-row {
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  margin-bottom: 0.25rem;
}

.header-row h3 {
  margin: 0;
  font-size: 0.8rem;
  color: #333;
  transition: color 0.2s;
  line-height: 1.2;
}

.title-link {
  text-decoration: none;
  color: inherit;
}

.title-link:hover h3 {
  color: #0066cc;
  text-decoration: underline;
}

.text-content p {
  margin: 0;
  font-size: 0.6rem;
  line-height: 1.4;
  color: #666;
}
</style>