---
layout: project
permalink: /:title/
category: projects

meta:
  keywords: "Tactile, Texture, Machine Learning"

project:
  title: "MyCobot280 M5 Projects"
  type: "Jekyll"
  url: "https://github.com/menonjay85/mycobot280-basics"
  logo: "/assets/4_prep.gif"
  tech: "myCobot, Raspberry Pi, Jetson Nano, OpenCV, Python,"

youtubeId: TpbLKVcOYL4
youtubeId2: 0ojuixPW3sk
---

<!-- ### Abstract -->

This showcases a collection of projects developed using the myCobot 280 M5 (Raspberry Pi and Jetson Nano), a compact six-axis collaborative robotic arm. The projects span various applications, highlighting the versatility and precision of the robot in fields such as automation, education, and human-robot interaction. Key implementations include pick-and-place tasks, letter writing and gesture-controlled robotic movement. Additionally, some projects explore programming techniques, including computer vision integration and Python-based automation scripts. Through these endeavors, the portfolio demonstrates the myCobot 280 M5â€™s potential to simplify complex tasks, promote hands-on learning, and inspire innovative solutions in robotics. <br><br>

<br>
{% include youtubePlayer.html id=page.youtubeId %}
<br>



<br>
{% include youtubePlayer.html id=page.youtubeId2 %}
<br>

<!-- ![Record Needle](/assets/images/projects/texture/record_needle.png)
<center><h2>A record cartridge, similar to what was used for classification </h2></center>


Additionally, a textural dataset was developed, consisting of eleven classes of both similar and varying textures. Multiple classifiers were used to compare with the existing literature. The best performing were found using PCA, with 99.8% test accuracy for Support Vector Machines, and 99.7% for Extra Trees and Random Forest Classifiers. Additionally, an Extra Trees Classifier using manual feature selection achieves 76.6% accuracy on only 10 milliseconds of sampling time. <br><br>

![Textures Used](/assets/images/projects/texture/texture_dataset.png)
<center><h2>The textures in the dataset. See report for full list of materials</h2></center>


These results match and exceed the current state-of-art performances while using a third or less training data on a similar set of classes, while using an inexpensive COTS sensor with two channels, as opposed to similar works which almost universally use sensors that are either 1. Custom, without instructions, 2. Expensive, or 3. Have many more input channels.<br><br> -->


<!-- ### More Information

Click <a href="https://youtu.be/TPY07R9Mu50" target="_blank"><u>here</u></a> to watch the corresponding presentation for this project. For even more information, <a href="https://drive.google.com/file/d/1u7AozTrO2Hw2sq41u9TIP8lyHH0yUuEb/view?usp=sharing" target="_blank"><u>this report</u></a> provides more detail on the implementation, novelty, and more. <br><br>

<br><br> -->

### Future Work
Building on the existing projects with the myCobot 280 M5, future work will explore more advanced functionalities and expand the application scope of the robotic arm. Planned areas of development include:
<br>
1. Cloud Robotics: Integrating cloud-based platforms for remote monitoring, control, and collaborative learning, allowing multiple robots to operate in sync.
<br>
2. Expanded Human-Robot Interaction (HRI): Creating more intuitive interfaces, such as voice control and AR-based interaction, to improve ease of use.
<br>
3. Educational Modules and Tutorials: Developing structured educational content to make myCobot 280 M5 accessible to students and researchers.
<br>
4. Improved Payload Handling: Exploring hardware enhancements and algorithmic optimizations to improve payload capacity and accuracy.
<br><br>